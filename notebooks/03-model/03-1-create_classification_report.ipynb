{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db552f",
   "metadata": {
    "papermill": {
     "duration": 13.848706,
     "end_time": "2023-12-11T14:28:19.724354",
     "exception": false,
     "start_time": "2023-12-11T14:28:05.875648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import src\n",
    "from src.bert import training\n",
    "from src.bert.dataset import PBertDataset\n",
    "from src.bert.dataset.strategies import MLMin1PopIdeol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ed884b",
   "metadata": {
    "papermill": {
     "duration": 0.010472,
     "end_time": "2023-12-11T14:28:19.784537",
     "exception": false,
     "start_time": "2023-12-11T14:28:19.774065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EXCLUDE_CODERS = []\n",
    "\n",
    "THRESHOLDS = {0: 0.415961, 1: 0.295400, 2: 0.429109, 3: 0.302714}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65c399",
   "metadata": {
    "papermill": {
     "duration": 9.430651,
     "end_time": "2023-12-11T14:28:29.223764",
     "exception": false,
     "start_time": "2023-12-11T14:28:19.793113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"luerhard/PopBERT\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"luerhard/PopBERT\")\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9d3fd",
   "metadata": {
    "papermill": {
     "duration": 0.192511,
     "end_time": "2023-12-11T14:28:29.429987",
     "exception": false,
     "start_time": "2023-12-11T14:28:29.237476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = PBertDataset.from_disk(\n",
    "    path=src.PATH / \"data/bert/test.csv.zip\",\n",
    "    label_strategy=MLMin1PopIdeol(),\n",
    "    exclude_coders=EXCLUDE_CODERS,\n",
    ")\n",
    "\n",
    "collate_fn = test.create_collate_fn(tokenizer)\n",
    "test_loader = DataLoader(test, collate_fn=collate_fn, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb649c3",
   "metadata": {
    "papermill": {
     "duration": 0.010861,
     "end_time": "2023-12-11T14:28:29.448667",
     "exception": false,
     "start_time": "2023-12-11T14:28:29.437806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_thresh(y_proba, thresholds: dict):\n",
    "    y_proba = y_proba.copy()\n",
    "    for dim, thresh in thresholds.items():\n",
    "        y_proba[:, dim] = np.where(y_proba[:, dim] > thresh, 1, 0)\n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abe271",
   "metadata": {
    "papermill": {
     "duration": 7.451196,
     "end_time": "2023-12-11T14:28:36.909992",
     "exception": false,
     "start_time": "2023-12-11T14:28:29.458796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch in test_loader:\n",
    "        encodings = batch[\"encodings\"]\n",
    "        encodings = encodings.to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        out = model(**encodings)\n",
    "        preds = torch.nn.functional.sigmoid(out.logits)\n",
    "        y_true.extend(batch[\"labels\"].numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "    y_pred_05 = np.where(np.array(y_pred) > 0.5, 1, 0)\n",
    "    y_pred_thresh = apply_thresh(np.array(y_pred), THRESHOLDS)\n",
    "    y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70900c0",
   "metadata": {
    "papermill": {
     "duration": 0.08757,
     "end_time": "2023-12-11T14:28:37.008340",
     "exception": false,
     "start_time": "2023-12-11T14:28:36.920770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       elite       0.82      0.86      0.84       648\n",
      "    pplcentr       0.77      0.60      0.67       322\n",
      "        left       0.71      0.75      0.73       279\n",
      "       right       0.77      0.57      0.65       155\n",
      "\n",
      "   micro avg       0.78      0.75      0.76      1404\n",
      "   macro avg       0.77      0.69      0.72      1404\n",
      "weighted avg       0.78      0.75      0.76      1404\n",
      " samples avg       0.39      0.38      0.38      1404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bwfor/home/st/st_st/st_ac138201/bert_populism/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gpfs/bwfor/home/st/st_st/st_ac138201/bert_populism/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred_05, target_names=[\"elite\", \"pplcentr\", \"left\", \"right\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe7777",
   "metadata": {
    "papermill": {
     "duration": 0.023986,
     "end_time": "2023-12-11T14:28:37.040148",
     "exception": false,
     "start_time": "2023-12-11T14:28:37.016162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       elite       0.81      0.88      0.84       648\n",
      "    pplcentr       0.70      0.73      0.71       322\n",
      "        left       0.69      0.77      0.73       279\n",
      "       right       0.68      0.66      0.67       155\n",
      "\n",
      "   micro avg       0.75      0.80      0.77      1404\n",
      "   macro avg       0.72      0.76      0.74      1404\n",
      "weighted avg       0.75      0.80      0.77      1404\n",
      " samples avg       0.41      0.40      0.40      1404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bwfor/home/st/st_st/st_ac138201/bert_populism/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gpfs/bwfor/home/st/st_st/st_ac138201/bert_populism/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true, y_pred_thresh, target_names=[\"elite\", \"pplcentr\", \"left\", \"right\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7eab9e",
   "metadata": {
    "papermill": {
     "duration": 0.033298,
     "end_time": "2023-12-11T14:28:37.078202",
     "exception": false,
     "start_time": "2023-12-11T14:28:37.044904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save_pretrained(src.PATH / \"tmp/PopBERT_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_populism",
   "language": "python",
   "name": "bert_populism"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.108764,
   "end_time": "2023-12-11T14:28:40.448048",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/03-model/03-1-create_classification_report.ipynb",
   "output_path": "notebooks/03-model/03-1-create_classification_report.ipynb",
   "parameters": {},
   "start_time": "2023-12-11T14:28:03.339284",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
