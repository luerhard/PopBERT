{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from transformers import logging\n",
    "import pandas as pd\n",
    "import src\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMIT_HASH = \"cf44004e90045cde298e28605ff105747d58aa7a\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"luerhard/PopBERT\", revision=COMMIT_HASH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"luerhard/PopBERT\", revision=COMMIT_HASH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(src.PATH / \"data/raw/sentences.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_batches(df, batch_size):\n",
    "    i = 0\n",
    "    while (i + batch_size) <= len(df):\n",
    "        slice_df = df.iloc[i : i + batch_size]\n",
    "        i += batch_size\n",
    "        yield slice_df.to_dict(orient=\"list\")\n",
    "    if (i + batch_size) != len(df):\n",
    "        slice_df = df.iloc[i:]\n",
    "        yield slice_df.to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.inference_mode():\n",
    "    for batch in iter_batches(df, 2):\n",
    "        ids, text = batch[\"sample_id\"], batch[\"text\"]\n",
    "        encodings = tokenizer(text, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "        out = model(**encodings)\n",
    "        proba_tensor = torch.nn.functional.sigmoid(out.logits)\n",
    "        probas = proba_tensor.cpu().detach().numpy()\n",
    "        \n",
    "        result = pd.DataFrame(probas)\n",
    "        result.columns = [\"elite\", \"pplcentr\", \"left\", \"right\"]\n",
    "        result[\"sample_id\"] = ids\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.concat(results)\n",
    "out = out[[\"sample_id\", \"elite\", \"pplcentr\", \"left\", \"right\"]]\n",
    "out.to_parquet(src.PATH / \"data/interim/sentence_predictions.parquet.gzip\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
